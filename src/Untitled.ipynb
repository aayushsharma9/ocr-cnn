{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 : 99.41543722909293 %                               \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 62, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 60, 60, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 128)       131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 48)                614448    \n",
      "=================================================================\n",
      "Total params: 940,400\n",
      "Trainable params: 939,568\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      " 830/1545 [===============>..............] - ETA: 15:45 - loss: 2.2387 - accuracy: 0.5170 - sparse_categorical_accuracy: 0.5170 - mean_squared_error: 756.1791 - mean_absolute_error: 24.6143"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, CSVLogger\n",
    "\n",
    "def classTextToInt(row_label):\n",
    "    switcher = {\n",
    "        '1': 1,\n",
    "        '2': 2,\n",
    "        '3': 3,\n",
    "        '4': 4,\n",
    "        '5': 5,\n",
    "        '6': 6,\n",
    "        '7': 7,\n",
    "        '8': 8,\n",
    "        '9': 9,\n",
    "        '0': 10,\n",
    "        'a': 37,\n",
    "        'b': 38,\n",
    "        'c': 13,\n",
    "        'd': 39,\n",
    "        'e': 40,\n",
    "        'f': 41,\n",
    "        'g': 42,\n",
    "        'h': 43,\n",
    "        'i': 19,\n",
    "        'j': 20,\n",
    "        'k': 21,\n",
    "        'l': 22,\n",
    "        'm': 23,\n",
    "        'n': 44,\n",
    "        'o': 25,\n",
    "        'p': 26,\n",
    "        'q': 45,\n",
    "        'r': 46,\n",
    "        's': 29,\n",
    "        't': 46,\n",
    "        'u': 31,\n",
    "        'v': 32,\n",
    "        'w': 33,\n",
    "        'x': 34,\n",
    "        'y': 35,\n",
    "        'z': 36,\n",
    "        'A': 11,\n",
    "        'B': 12,\n",
    "        'C': 13,\n",
    "        'D': 14,\n",
    "        'E': 15,\n",
    "        'F': 16,\n",
    "        'G': 17,\n",
    "        'H': 18,\n",
    "        'I': 19,\n",
    "        'J': 20,\n",
    "        'K': 21,\n",
    "        'L': 22,\n",
    "        'M': 23,\n",
    "        'N': 24,\n",
    "        'O': 25,\n",
    "        'P': 26,\n",
    "        'Q': 27,\n",
    "        'R': 28,\n",
    "        'S': 29,\n",
    "        'T': 30,\n",
    "        'U': 31,\n",
    "        'V': 32,\n",
    "        'W': 33,\n",
    "        'X': 34,\n",
    "        'Y': 35,\n",
    "        'Z': 36,\n",
    "        'Random': 47\n",
    "    }\n",
    "    return switcher.get(row_label, None)\n",
    "\n",
    "folderToFind = \"by_class/\"\n",
    "offsetLength = len(folderToFind)\n",
    "\n",
    "def imageResize (image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    return resized\n",
    "\n",
    "def imageGray (image):\n",
    "    imageG = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return imageG\n",
    "\n",
    "def downScaleImage(path, index):\n",
    "    image = cv2.imread(path)   \n",
    "    grayImage = imageGray(image)\n",
    "    thresh = cv2.adaptiveThreshold(grayImage, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 101, 40)\n",
    "    resizedImage = imageResize(thresh, height = 64)\n",
    "    arr = array(resizedImage)\n",
    "    return arr\n",
    "\n",
    "SAVE_PATH = \"logs/modelsBalancedComplete\"\n",
    "num_classes = 48\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "df1 = pd.read_csv('trainingRecords.csv')\n",
    "for index, row in df1.iterrows():\n",
    "    if index % 1000 == 0:\n",
    "        print('Progress:',(index/len(df1))*100, '%                              ', end='\\r')\n",
    "    temp = downScaleImage(row['fileName'], index)\n",
    "    filePath = row['fileName']\n",
    "    fileClass = filePath[filePath.find(folderToFind) + offsetLength]\n",
    "    toAdd = temp.ravel()\n",
    "    X_train.append(toAdd)\n",
    "    Y_train.append(classTextToInt(fileClass))\n",
    "\n",
    "X_train = array(X_train)\n",
    "Y_train = array(Y_train)\n",
    "X_train = np.reshape(X_train, (-1, 64, 64, 1))\n",
    "# Y_train = to_categorical(Y_train, num_classes)\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "df1 = pd.read_csv('validationRecords.csv')\n",
    "for index, row in df1.iterrows():\n",
    "    if index % 1000 == 0:\n",
    "        print('Progress:',(index/len(df1))*100, '%                              ', end='\\r')\n",
    "    temp = downScaleImage(row['fileName'], index)\n",
    "    filePath = row['fileName']\n",
    "    fileClass = filePath[filePath.find(folderToFind) + offsetLength]\n",
    "    toAdd = temp.ravel()\n",
    "    X_test.append(toAdd)\n",
    "    Y_test.append(classTextToInt(fileClass))\n",
    "\n",
    "X_test = array(X_test)\n",
    "Y_test = array(Y_test)\n",
    "X_test = np.reshape(X_test, (-1, 64, 64, 1))\n",
    "# Y_test = to_categorical(Y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=15, zoom_range = 0.15, width_shift_range=0.1, height_shift_range=0.1)\n",
    "\n",
    "nets = 1\n",
    "model = [0] * nets\n",
    "tensorboard = [0] * nets\n",
    "csv_logger = [0] * nets\n",
    "\n",
    "for j in range(nets):\n",
    "    model[j] = Sequential()\n",
    "\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (64, 64, 1)))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dropout(0.4))\n",
    "    model[j].add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model[j].compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy', 'sparse_categorical_accuracy', 'mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "    NAME = \"{}-conv-{}-nodes-{}-dense{}\".format(7, 48, 1, int(time.time()))\n",
    "    tensorboard[j] = TensorBoard(log_dir='{}/{}______{}'.format(SAVE_PATH, NAME, j))\n",
    "    csv_logger[j] = CSVLogger('{}/csvlogs/{}__{}.csv'.format(SAVE_PATH, NAME, j), separator=',', append=False)\n",
    "\n",
    "    print('Model', j+1, ':')\n",
    "    model[j].summary()\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "epochs = 30\n",
    "history = [0] * nets\n",
    "\n",
    "for j in range(nets):\n",
    "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.2)\n",
    "    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n",
    "        epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,  \n",
    "        validation_data = (X_val2,Y_val2),\n",
    "        callbacks=[annealer, tensorboard[j], csv_logger[j]])\n",
    "#     print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "#         j+1,epochs,max(history[j].history['acc']),max(history[j].history['val_acc']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(nets):\n",
    "    model[j].evaluate(X_test, Y_test)\n",
    "\n",
    "for j in range(nets):\n",
    "    model[j].save(\"{}/model{0:d}.hdf5\".format(SAVE_PATH, j+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
