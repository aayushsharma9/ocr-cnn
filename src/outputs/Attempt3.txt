/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
(592713, 784)
(592713, 28, 28, 1)
(592713, 28, 28, 1)
WARNING: Logging before flag parsing goes to stderr.
W0905 17:46:21.913841 140215865779840 deprecation.py:506] From /usr/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 32)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         
_________________________________________________________________
dropout (Dropout)            (None, 3, 3, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 576)               0         
_________________________________________________________________
dense (Dense)                (None, 256)               147712    
_________________________________________________________________
dense_1 (Dense)              (None, 128)               32896     
_________________________________________________________________
dense_2 (Dense)              (None, 62)                7998      
=================================================================
Total params: 244,350
Trainable params: 244,350
Non-trainable params: 0
_________________________________________________________________
Train on 474170 samples, validate on 118543 samples
2019-09-05 17:46:22.493347: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-05 17:46:22.518578: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2593000000 Hz
2019-09-05 17:46:22.518913: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a0764d9f00 executing computations on platform Host. Devices:
2019-09-05 17:46:22.518953: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-05 17:46:22.598702: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Epoch 1/10
2019-09-05 17:46:22.945891: W tensorflow/core/framework/allocator.cc:107] Allocation of 20321280 exceeds 10% of system memory.
2019-09-05 17:46:22.946000: W tensorflow/core/framework/allocator.cc:107] Allocation of 20321280 exceeds 10% of system memory.
2019-09-05 17:46:23.014658: I tensorflow/core/profiler/lib/profiler_session.cc:174] Profiler session started.
   128/474170 [..............................] - ETA: 20:08 - loss: 4.1307 - acc: 0.00782019-09-05 17:46:23.084219: W tensorflow/core/framework/allocator.cc:107] Allocation of 20321280 exceeds 10% of system memory.
2019-09-05 17:46:23.084146: W tensorflow/core/framework/allocator.cc:107] Allocation of 20321280 exceeds 10% of system memory.
   256/474170 [..............................] - ETA: 14:25 - loss: 4.1242 - acc: 0.02732019-09-05 17:46:23.211736: W tensorflow/core/framework/allocator.cc:107] Allocation of 20321280 exceeds 10% of system memory.
2019-09-05 17:46:23.211736: W tensorflow/core/framework/allocator.cc:107] Allocation of 20321280 exceeds 10% of system memory.
474170/474170 [==============================] - 341s 719us/sample - loss: 0.6061 - acc: 0.8166 - val_loss: 0.3684 - val_acc: 0.8769
Epoch 2/10
474170/474170 [==============================] - 336s 708us/sample - loss: 0.3658 - acc: 0.8797 - val_loss: 0.3298 - val_acc: 0.8907
Epoch 3/10
474170/474170 [==============================] - 329s 694us/sample - loss: 0.3270 - acc: 0.8903 - val_loss: 0.3111 - val_acc: 0.8964
Epoch 4/10
474170/474170 [==============================] - 330s 696us/sample - loss: 0.3071 - acc: 0.8956 - val_loss: 0.3028 - val_acc: 0.8989
Epoch 5/10
474170/474170 [==============================] - 327s 690us/sample - loss: 0.2936 - acc: 0.8998 - val_loss: 0.2997 - val_acc: 0.8994
Epoch 6/10
474170/474170 [==============================] - 331s 699us/sample - loss: 0.2822 - acc: 0.9034 - val_loss: 0.2889 - val_acc: 0.9021
Epoch 7/10
474170/474170 [==============================] - 330s 695us/sample - loss: 0.2741 - acc: 0.9054 - val_loss: 0.2886 - val_acc: 0.9028
Epoch 8/10
474170/474170 [==============================] - 324s 684us/sample - loss: 0.2667 - acc: 0.9075 - val_loss: 0.2893 - val_acc: 0.9028
Epoch 9/10
474170/474170 [==============================] - 321s 678us/sample - loss: 0.2622 - acc: 0.9087 - val_loss: 0.2868 - val_acc: 0.9038
Epoch 10/10
474170/474170 [==============================] - 320s 674us/sample - loss: 0.2556 - acc: 0.9103 - val_loss: 0.2859 - val_acc: 0.9038
142700/142700 [==============================] - 30s 213us/sample - loss: 0.5248 - acc: 0.8065