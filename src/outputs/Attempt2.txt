model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=[tensorboard])

/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
(592713, 784)
(592713, 28, 28, 1)
(592713, 28, 28, 1)
WARNING: Logging before flag parsing goes to stderr.
W0905 15:00:18.212344 139952259819136 deprecation.py:506] From /usr/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 32)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 576)               0         
_________________________________________________________________
dense (Dense)                (None, 128)               73856     
_________________________________________________________________
dense_1 (Dense)              (None, 62)                7998      
=================================================================
Total params: 137,598
Trainable params: 137,598
Non-trainable params: 0
_________________________________________________________________
Train on 474170 samples, validate on 118543 samples
2019-09-05 15:00:18.689214: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-05 15:00:18.709579: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2593000000 Hz
2019-09-05 15:00:18.709977: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555acad67d40 executing computations on platform Host. Devices:
2019-09-05 15:00:18.710024: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-05 15:00:18.776752: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Epoch 1/20
2019-09-05 15:00:19.004278: I tensorflow/core/profiler/lib/profiler_session.cc:174] Profiler session started.
474170/474170 [==============================] - 380s 801us/sample - loss: 0.5019 - acc: 0.8446 - val_loss: 0.3617 - val_acc: 0.8813
Epoch 2/20
474170/474170 [==============================] - 378s 797us/sample - loss: 0.3426 - acc: 0.8865 - val_loss: 0.3473 - val_acc: 0.8860
Epoch 3/20
474170/474170 [==============================] - 321s 678us/sample - loss: 0.3144 - acc: 0.8947 - val_loss: 0.3190 - val_acc: 0.8929
Epoch 4/20
474170/474170 [==============================] - 319s 672us/sample - loss: 0.2985 - acc: 0.8991 - val_loss: 0.3185 - val_acc: 0.8961
Epoch 5/20
474170/474170 [==============================] - 318s 671us/sample - loss: 0.2881 - acc: 0.9022 - val_loss: 0.3155 - val_acc: 0.8954
Epoch 6/20
474170/474170 [==============================] - 318s 670us/sample - loss: 0.2810 - acc: 0.9037 - val_loss: 0.3275 - val_acc: 0.8933
Epoch 7/20
474170/474170 [==============================] - 334s 705us/sample - loss: 0.2742 - acc: 0.9060 - val_loss: 0.3254 - val_acc: 0.8934
Epoch 8/20
474170/474170 [==============================] - 361s 761us/sample - loss: 0.2694 - acc: 0.9070 - val_loss: 0.3143 - val_acc: 0.8983
Epoch 9/20
474170/474170 [==============================] - 332s 700us/sample - loss: 0.2658 - acc: 0.9080 - val_loss: 0.3170 - val_acc: 0.8966
Epoch 10/20
474170/474170 [==============================] - 352s 742us/sample - loss: 0.2628 - acc: 0.9092 - val_loss: 0.3270 - val_acc: 0.8948
Epoch 11/20
474170/474170 [==============================] - 358s 755us/sample - loss: 0.2604 - acc: 0.9095 - val_loss: 0.3202 - val_acc: 0.8979
Epoch 12/20
474170/474170 [==============================] - 318s 671us/sample - loss: 0.2570 - acc: 0.9107 - val_loss: 0.3330 - val_acc: 0.8966
Epoch 13/20
474170/474170 [==============================] - 318s 670us/sample - loss: 0.2556 - acc: 0.9108 - val_loss: 0.3386 - val_acc: 0.8943
Epoch 14/20
474170/474170 [==============================] - 317s 670us/sample - loss: 0.2538 - acc: 0.9114 - val_loss: 0.3400 - val_acc: 0.8950
Epoch 15/20
474170/474170 [==============================] - 340s 718us/sample - loss: 0.2521 - acc: 0.9121 - val_loss: 0.3409 - val_acc: 0.8958
Epoch 16/20
474170/474170 [==============================] - 361s 761us/sample - loss: 0.2506 - acc: 0.9122 - val_loss: 0.3435 - val_acc: 0.8945
Epoch 17/20
474170/474170 [==============================] - 349s 737us/sample - loss: 0.2492 - acc: 0.9127 - val_loss: 0.3419 - val_acc: 0.8966
Epoch 18/20
474170/474170 [==============================] - 352s 742us/sample - loss: 0.2477 - acc: 0.9135 - val_loss: 0.3536 - val_acc: 0.8959
Epoch 19/20
474170/474170 [==============================] - 358s 755us/sample - loss: 0.2471 - acc: 0.9137 - val_loss: 0.3489 - val_acc: 0.8963
Epoch 20/20
474170/474170 [==============================] - 318s 670us/sample - loss: 0.2456 - acc: 0.9138 - val_loss: 0.3563 - val_acc: 0.8947
142700/142700 [==============================] - 26s 184us/sample - loss: 0.6402 - acc: 0.7955