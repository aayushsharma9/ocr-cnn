python3.7 ocr-train3-single.py 
WARNING: Logging before flag parsing goes to stderr.
W0918 19:54:24.830547 139692013069952 __init__.py:687] 

  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.

  Please upgrade your code to TensorFlow 2.0:
    * https://www.tensorflow.org/beta/guide/migration_guide

  Or install the latest stable TensorFlow 1.X release:
    * `pip install -U "tensorflow==1.*"`

  Otherwise your code may be broken by the change.

  
(88800, 784)
(88800, 28, 28, 1)
(88800, 28, 28, 1)
Name: 7-conv-128-nodes-1-dense1568816670
W0918 19:54:30.229771 139692013069952 deprecation.py:506] From /usr/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1633: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 26, 26, 32)        320       
_________________________________________________________________
batch_normalization (BatchNo (None, 26, 26, 32)        128       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      
_________________________________________________________________
batch_normalization_1 (Batch (None, 24, 24, 32)        128       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 12, 12, 32)        25632     
_________________________________________________________________
batch_normalization_2 (Batch (None, 12, 12, 32)        128       
_________________________________________________________________
dropout (Dropout)            (None, 12, 12, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     
_________________________________________________________________
batch_normalization_3 (Batch (None, 10, 10, 64)        256       
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     
_________________________________________________________________
batch_normalization_4 (Batch (None, 8, 8, 64)          256       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 4, 4, 64)          102464    
_________________________________________________________________
batch_normalization_5 (Batch (None, 4, 4, 64)          256       
_________________________________________________________________
dropout_1 (Dropout)          (None, 4, 4, 64)          0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 1, 1, 128)         131200    
_________________________________________________________________
batch_normalization_6 (Batch (None, 1, 1, 128)         512       
_________________________________________________________________
flatten (Flatten)            (None, 128)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense (Dense)                (None, 27)                3483      
=================================================================
Total params: 329,435
Trainable params: 328,603
Non-trainable params: 832
_________________________________________________________________
W0918 19:54:31.312242 139692013069952 deprecation.py:323] From /usr/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:468: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Apply a constraint manually following the optimizer update step.
Train on 71040 samples, validate on 17760 samples
2019-09-18 19:54:31.616500: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-18 19:54:31.636124: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2593000000 Hz
2019-09-18 19:54:31.636458: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5590b92862e0 executing computations on platform Host. Devices:
2019-09-18 19:54:31.636489: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
Epoch 1/50
2019-09-18 19:54:32.467202: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.
71040/71040 [==============================] - 199s 3ms/sample - loss: 0.6986 - acc: 0.7907 - val_loss: 0.2576 - val_acc: 0.9160
Epoch 2/50
71040/71040 [==============================] - 199s 3ms/sample - loss: 0.3243 - acc: 0.8949 - val_loss: 0.2332 - val_acc: 0.9221
Epoch 3/50
71040/71040 [==============================] - 199s 3ms/sample - loss: 0.2757 - acc: 0.9095 - val_loss: 0.2130 - val_acc: 0.9279
Epoch 4/50
71040/71040 [==============================] - 188s 3ms/sample - loss: 0.2485 - acc: 0.9175 - val_loss: 0.1850 - val_acc: 0.9374
Epoch 5/50
71040/71040 [==============================] - 199s 3ms/sample - loss: 0.2239 - acc: 0.9251 - val_loss: 0.1762 - val_acc: 0.9416
Epoch 6/50
71040/71040 [==============================] - 200s 3ms/sample - loss: 0.2129 - acc: 0.9273 - val_loss: 0.1768 - val_acc: 0.9407
Epoch 7/50
71040/71040 [==============================] - 202s 3ms/sample - loss: 0.2031 - acc: 0.9313 - val_loss: 0.1746 - val_acc: 0.9412
Epoch 8/50
71040/71040 [==============================] - 200s 3ms/sample - loss: 0.1900 - acc: 0.9345 - val_loss: 0.1642 - val_acc: 0.9465
Epoch 9/50
71040/71040 [==============================] - 200s 3ms/sample - loss: 0.1806 - acc: 0.9376 - val_loss: 0.1635 - val_acc: 0.9459
Epoch 10/50
71040/71040 [==============================] - 199s 3ms/sample - loss: 0.1785 - acc: 0.9377 - val_loss: 0.1568 - val_acc: 0.9485
Epoch 11/50
71040/71040 [==============================] - 200s 3ms/sample - loss: 0.1691 - acc: 0.9410 - val_loss: 0.1567 - val_acc: 0.9497
Epoch 12/50
71040/71040 [==============================] - 200s 3ms/sample - loss: 0.1634 - acc: 0.9431 - val_loss: 0.1572 - val_acc: 0.9492
Epoch 13/50
71040/71040 [==============================] - 199s 3ms/sample - loss: 0.1600 - acc: 0.9441 - val_loss: 0.1550 - val_acc: 0.9499
Epoch 14/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1584 - acc: 0.9446 - val_loss: 0.1550 - val_acc: 0.9498
Epoch 15/50
71040/71040 [==============================] - 197s 3ms/sample - loss: 0.1513 - acc: 0.9455 - val_loss: 0.1576 - val_acc: 0.9498
Epoch 16/50
71040/71040 [==============================] - 176s 2ms/sample - loss: 0.1491 - acc: 0.9465 - val_loss: 0.1523 - val_acc: 0.9517
Epoch 17/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1445 - acc: 0.9485 - val_loss: 0.1548 - val_acc: 0.9510
Epoch 18/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1392 - acc: 0.9493 - val_loss: 0.1588 - val_acc: 0.9492
Epoch 19/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1398 - acc: 0.9486 - val_loss: 0.1566 - val_acc: 0.9503
Epoch 20/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1347 - acc: 0.9498 - val_loss: 0.1590 - val_acc: 0.9503
Epoch 21/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1314 - acc: 0.9516 - val_loss: 0.1580 - val_acc: 0.9513
Epoch 22/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1330 - acc: 0.9510 - val_loss: 0.1588 - val_acc: 0.9507
Epoch 23/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1285 - acc: 0.9515 - val_loss: 0.1612 - val_acc: 0.9511
Epoch 24/50
71040/71040 [==============================] - 197s 3ms/sample - loss: 0.1278 - acc: 0.9515 - val_loss: 0.1627 - val_acc: 0.9497
Epoch 25/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1242 - acc: 0.9538 - val_loss: 0.1589 - val_acc: 0.9498
Epoch 26/50
71040/71040 [==============================] - 199s 3ms/sample - loss: 0.1209 - acc: 0.9539 - val_loss: 0.1589 - val_acc: 0.9523
Epoch 27/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1201 - acc: 0.9549 - val_loss: 0.1633 - val_acc: 0.9511
Epoch 28/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1203 - acc: 0.9551 - val_loss: 0.1644 - val_acc: 0.9523
Epoch 29/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1182 - acc: 0.9548 - val_loss: 0.1604 - val_acc: 0.9505
Epoch 30/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1156 - acc: 0.9559 - val_loss: 0.1657 - val_acc: 0.9495
Epoch 31/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1152 - acc: 0.9562 - val_loss: 0.1615 - val_acc: 0.9525
Epoch 32/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1137 - acc: 0.9574 - val_loss: 0.1586 - val_acc: 0.9500
Epoch 33/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1099 - acc: 0.9586 - val_loss: 0.1658 - val_acc: 0.9507
Epoch 34/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1108 - acc: 0.9574 - val_loss: 0.1693 - val_acc: 0.9511
Epoch 35/50
71040/71040 [==============================] - 189s 3ms/sample - loss: 0.1094 - acc: 0.9579 - val_loss: 0.1710 - val_acc: 0.9512
Epoch 36/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1067 - acc: 0.9586 - val_loss: 0.1643 - val_acc: 0.9514
Epoch 37/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1057 - acc: 0.9589 - val_loss: 0.1685 - val_acc: 0.9525
Epoch 38/50
71040/71040 [==============================] - 197s 3ms/sample - loss: 0.1049 - acc: 0.9592 - val_loss: 0.1697 - val_acc: 0.9520
Epoch 39/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1035 - acc: 0.9595 - val_loss: 0.1706 - val_acc: 0.9517
Epoch 40/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1015 - acc: 0.9609 - val_loss: 0.1708 - val_acc: 0.9519
Epoch 41/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.1026 - acc: 0.9607 - val_loss: 0.1681 - val_acc: 0.9520
Epoch 42/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.0975 - acc: 0.9624 - val_loss: 0.1742 - val_acc: 0.9528
Epoch 43/50
71040/71040 [==============================] - 187s 3ms/sample - loss: 0.1015 - acc: 0.9607 - val_loss: 0.1695 - val_acc: 0.9512
Epoch 44/50
71040/71040 [==============================] - 200s 3ms/sample - loss: 0.0980 - acc: 0.9620 - val_loss: 0.1730 - val_acc: 0.9517
Epoch 45/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.0980 - acc: 0.9611 - val_loss: 0.1738 - val_acc: 0.9514
Epoch 46/50
71040/71040 [==============================] - 197s 3ms/sample - loss: 0.0942 - acc: 0.9629 - val_loss: 0.1796 - val_acc: 0.9514
Epoch 47/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.0954 - acc: 0.9627 - val_loss: 0.1745 - val_acc: 0.9515
Epoch 48/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.0944 - acc: 0.9624 - val_loss: 0.1837 - val_acc: 0.9505
Epoch 49/50
71040/71040 [==============================] - 197s 3ms/sample - loss: 0.0917 - acc: 0.9639 - val_loss: 0.1758 - val_acc: 0.9528
Epoch 50/50
71040/71040 [==============================] - 198s 3ms/sample - loss: 0.0911 - acc: 0.9635 - val_loss: 0.1790 - val_acc: 0.9519
14800/14800 [==============================] - 10s 697us/sample - loss: 0.1999 - acc: 0.9420