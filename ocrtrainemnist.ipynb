{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0910 13:52:13.688387 140594712012416 __init__.py:687] \n",
      "\n",
      "  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n",
      "\n",
      "  Please upgrade your code to TensorFlow 2.0:\n",
      "    * https://www.tensorflow.org/beta/guide/migration_guide\n",
      "\n",
      "  Or install the latest stable TensorFlow 1.X release:\n",
      "    * `pip install -U \"tensorflow==1.*\"`\n",
      "\n",
      "  Otherwise your code may be broken by the change.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import time\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_loadtxt(filename, delimiter=',', skiprows=0, dtype=np.float16, shape='auto'):\n",
    "    def iter_func():\n",
    "        with open(filename, 'r') as infile:\n",
    "            for _ in range(skiprows):\n",
    "                next(infile)\n",
    "            for line in infile:\n",
    "                line = line.rstrip().split(delimiter)\n",
    "                for item in line:\n",
    "                    yield dtype(item)\n",
    "        iter_loadtxt.rowlength = len(line)\n",
    "\n",
    "    data = np.fromiter(iter_func(), dtype=dtype)\n",
    "    if shape == 'auto':\n",
    "        data = data.reshape((-1, iter_loadtxt.rowlength))\n",
    "    else:\n",
    "        data = data.reshape(shape)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train loaded\n",
      "Y_train loaded\n",
      "X_test loaded\n",
      "Y_test loaded\n"
     ]
    }
   ],
   "source": [
    "X_train = iter_loadtxt('datasets/xTrain.csv', shape=(-1, 28, 28, 1))\n",
    "print('X_train loaded')\n",
    "Y_train = iter_loadtxt('datasets/yTrain.csv', dtype=int)\n",
    "print('Y_train loaded')\n",
    "\n",
    "X_test = iter_loadtxt('datasets/xTest.csv', shape=(-1, 28, 28, 1))\n",
    "print('X_test loaded')\n",
    "Y_test = iter_loadtxt('datasets/yTest.csv', dtype=int)\n",
    "print('Y_test loaded')\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=15, zoom_range = 0.15, width_shift_range=0.1, height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0910 14:01:20.638263 140594712012416 deprecation.py:506] From /usr/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1633: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 :\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 128)         131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 62)                7998      \n",
      "=================================================================\n",
      "Total params: 333,950\n",
      "Trainable params: 333,118\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nets = 1\n",
    "model = [0] *nets\n",
    "for j in range(nets):\n",
    "    model[j] = Sequential()\n",
    "\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dropout(0.4))\n",
    "    model[j].add(Dense(62, activation='softmax'))\n",
    "\n",
    "    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    print('Model', j+1, ':')\n",
    "    model[j].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "9814/9814 [==============================] - 1527s 156ms/step - loss: 0.6683 - acc: 0.7807 - val_loss: 0.4162 - val_acc: 0.8476\n",
      "Epoch 2/30\n",
      "9814/9814 [==============================] - 1533s 156ms/step - loss: 0.5039 - acc: 0.8255 - val_loss: 0.3985 - val_acc: 0.8527\n",
      "Epoch 3/30\n",
      "9814/9814 [==============================] - 1527s 156ms/step - loss: 0.4718 - acc: 0.8346 - val_loss: 0.3890 - val_acc: 0.8547\n",
      "Epoch 4/30\n",
      "9814/9814 [==============================] - 1513s 154ms/step - loss: 0.4545 - acc: 0.8398 - val_loss: 0.3788 - val_acc: 0.8574\n",
      "Epoch 5/30\n",
      "9814/9814 [==============================] - 1522s 155ms/step - loss: 0.4425 - acc: 0.8429 - val_loss: 0.3821 - val_acc: 0.8582\n",
      "Epoch 6/30\n",
      "9814/9814 [==============================] - 1481s 151ms/step - loss: 0.4341 - acc: 0.8456 - val_loss: 0.3612 - val_acc: 0.8647\n",
      "Epoch 7/30\n",
      "9814/9814 [==============================] - 1500s 153ms/step - loss: 0.4269 - acc: 0.8473 - val_loss: 0.3691 - val_acc: 0.8596\n",
      "Epoch 8/30\n",
      "9814/9814 [==============================] - 1530s 156ms/step - loss: 0.4217 - acc: 0.8493 - val_loss: 0.3775 - val_acc: 0.8608\n",
      "Epoch 9/30\n",
      "9814/9814 [==============================] - 1515s 154ms/step - loss: 0.4180 - acc: 0.8502 - val_loss: 0.3763 - val_acc: 0.8568\n",
      "Epoch 10/30\n",
      "9814/9814 [==============================] - 1478s 151ms/step - loss: 0.4138 - acc: 0.8516 - val_loss: 0.3721 - val_acc: 0.8591\n",
      "Epoch 11/30\n",
      "9814/9814 [==============================] - 1475s 150ms/step - loss: 0.4104 - acc: 0.8526 - val_loss: 0.3975 - val_acc: 0.8500\n",
      "Epoch 12/30\n",
      "9814/9814 [==============================] - 1500s 153ms/step - loss: 0.4070 - acc: 0.8538 - val_loss: 0.3665 - val_acc: 0.8569\n",
      "Epoch 13/30\n",
      "9814/9814 [==============================] - 1482s 151ms/step - loss: 0.4044 - acc: 0.8541 - val_loss: 0.3793 - val_acc: 0.8560\n",
      "Epoch 14/30\n",
      "9814/9814 [==============================] - 1478s 151ms/step - loss: 0.4019 - acc: 0.8549 - val_loss: 0.3730 - val_acc: 0.8567\n",
      "Epoch 15/30\n",
      "9814/9814 [==============================] - 1481s 151ms/step - loss: 0.4007 - acc: 0.8553 - val_loss: 0.3608 - val_acc: 0.8644\n",
      "Epoch 16/30\n",
      "9814/9814 [==============================] - 1479s 151ms/step - loss: 0.3984 - acc: 0.8564 - val_loss: 0.3674 - val_acc: 0.8600\n",
      "Epoch 17/30\n",
      "9814/9814 [==============================] - 1490s 152ms/step - loss: 0.3961 - acc: 0.8569 - val_loss: 0.3632 - val_acc: 0.8607\n",
      "Epoch 18/30\n",
      "9814/9814 [==============================] - 1488s 152ms/step - loss: 0.3953 - acc: 0.8569 - val_loss: 0.3623 - val_acc: 0.8636\n",
      "Epoch 19/30\n",
      "9814/9814 [==============================] - 1513s 154ms/step - loss: 0.3933 - acc: 0.8572 - val_loss: 0.3733 - val_acc: 0.8592\n",
      "Epoch 20/30\n",
      "9814/9814 [==============================] - 1503s 153ms/step - loss: 0.3915 - acc: 0.8579 - val_loss: 0.3645 - val_acc: 0.8610\n",
      "Epoch 21/30\n",
      "9814/9814 [==============================] - 1494s 152ms/step - loss: 0.3912 - acc: 0.8581 - val_loss: 0.3578 - val_acc: 0.8649\n",
      "Epoch 22/30\n",
      "9814/9814 [==============================] - 1527s 156ms/step - loss: 0.3896 - acc: 0.8585 - val_loss: 0.3716 - val_acc: 0.8590\n",
      "Epoch 23/30\n",
      "9814/9814 [==============================] - 1503s 153ms/step - loss: 0.3883 - acc: 0.8588 - val_loss: 0.3628 - val_acc: 0.8620\n",
      "Epoch 24/30\n",
      "9814/9814 [==============================] - 1498s 153ms/step - loss: 0.3871 - acc: 0.8590 - val_loss: 0.3810 - val_acc: 0.8556\n",
      "Epoch 25/30\n",
      "9814/9814 [==============================] - 1480s 151ms/step - loss: 0.3865 - acc: 0.8593 - val_loss: 0.3688 - val_acc: 0.8605\n",
      "Epoch 26/30\n",
      "9814/9814 [==============================] - 1503s 153ms/step - loss: 0.3855 - acc: 0.8594 - val_loss: 0.3687 - val_acc: 0.8600\n",
      "Epoch 27/30\n",
      "9814/9814 [==============================] - 1483s 151ms/step - loss: 0.3845 - acc: 0.8597 - val_loss: 0.3621 - val_acc: 0.8632\n",
      "Epoch 28/30\n",
      "9814/9814 [==============================] - 1483s 151ms/step - loss: 0.3829 - acc: 0.8602 - val_loss: 0.3555 - val_acc: 0.8649\n",
      "Epoch 29/30\n",
      "9814/9814 [==============================] - 1483s 151ms/step - loss: 0.3821 - acc: 0.8606 - val_loss: 0.3660 - val_acc: 0.8605\n",
      "Epoch 30/30\n",
      "9814/9814 [==============================] - 1485s 151ms/step - loss: 0.3819 - acc: 0.8604 - val_loss: 0.3606 - val_acc: 0.8639\n",
      "CNN 1: Epochs=30, Train accuracy=0.86062, Validation accuracy=0.86492\n"
     ]
    }
   ],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "epochs = 30\n",
    "history = [0] * nets\n",
    "\n",
    "for j in range(nets):\n",
    "    NAME = \"{}-model{}\".format(j+1, int(time.time()))\n",
    "    tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.1)\n",
    "    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n",
    "        epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,  \n",
    "        validation_data = (X_val2,Y_val2), callbacks=[annealer, tensorboard])\n",
    "    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "        j+1,epochs,max(history[j].history['acc']),max(history[j].history['val_acc']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116323/116323 [==============================] - 75s 641us/sample - loss: 0.3572 - acc: 0.8656\n"
     ]
    }
   ],
   "source": [
    "for j in range(nets):\n",
    "    model[j].evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(nets):\n",
    "    model[j].save(\"models2finalModel{0:d}.hdf5\".format(j+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
